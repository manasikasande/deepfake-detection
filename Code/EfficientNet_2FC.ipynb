{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet_2FC.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkXr4IiCbJ2G"
      },
      "outputs": [],
      "source": [
        "!pip3 install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PiRhPwvZQ8-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import glob\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "import json\n",
        "import copy\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import sys\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "eG87hfASgu1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load videos to memory\n",
        "\n",
        "video_files =  glob.glob('/content/drive/MyDrive/Colab Notebooks/Preprocess_dfdcfake/*.mp4')\n",
        "video_files += glob.glob('/content/drive/MyDrive/Colab Notebooks/Preprocess_FFReal/*.mp4')\n",
        "video_files += glob.glob('/content/drive/MyDrive/Colab Notebooks/Preprocess_FFFake/*.mp4')\n",
        "video_files += glob.glob('/content/drive/MyDrive/Colab Notebooks/Preprocess_dfdcreal/*.mp4')\n",
        "video_files += glob.glob('/content/drive/MyDrive/Colab Notebooks/Preprocess_CelebReal/*.mp4')\n",
        "video_files += glob.glob('/content/drive/MyDrive/Colab Notebooks/Preprocess_CelebFake/*.mp4')\n",
        "\n",
        "random.shuffle(video_files)\n",
        "random.shuffle(video_files)\n",
        "frame_count = []\n",
        "for video_file in video_files:\n",
        "  cap = cv2.VideoCapture(video_file)\n",
        "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<100):\n",
        "    video_files.remove(video_file)\n",
        "    continue\n",
        "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "print(\"frames are \" , frame_count)\n",
        "print(\"Total no of video: \" , len(frame_count))\n",
        "print('Average frame per video:',np.mean(frame_count))\n"
      ],
      "metadata": {
        "id": "a4YWaWATgxSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create custom dataset class\n",
        "\n",
        "class video_dataset(Dataset):\n",
        "    def __init__(self,video_names,labels,sequence_length,transform = None):\n",
        "        self.video_names = video_names\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.count = sequence_length\n",
        "    def __len__(self):\n",
        "        return len(self.video_names)\n",
        "    def __getitem__(self,idx):\n",
        "        video_path = self.video_names[idx]\n",
        "        frames = []\n",
        "        a = int(100/self.count)\n",
        "        first_frame = np.random.randint(0,a)\n",
        "        temp_video = video_path.split('/')[-1]\n",
        "        #print(temp_video)\n",
        "        label = self.labels.iloc[(labels.loc[labels[\"File\"] == temp_video].index.values[0]),1]\n",
        "        if(label == 'FAKE'):\n",
        "          label = 0\n",
        "        if(label == 'REAL'):\n",
        "          label = 1\n",
        "        for i,frame in enumerate(self.frame_extract(video_path)):\n",
        "          frames.append(self.transform(frame))\n",
        "          if(len(frames) == self.count):\n",
        "            break\n",
        "        frames = torch.stack(frames)\n",
        "        frames = frames[:self.count]\n",
        "        \n",
        "        return frames,label\n",
        "\n",
        "    def frame_extract(self,path):\n",
        "      vidObj = cv2.VideoCapture(path) \n",
        "      success = 1\n",
        "      while success:\n",
        "          success, image = vidObj.read()\n",
        "          if success:\n",
        "              yield image"
      ],
      "metadata": {
        "id": "mNtjUC4Tg0sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count the number of fake and real videos\n",
        "def number_of_real_and_fake_videos(data_list):\n",
        "  header_list = [\"File\",\"Label\"]\n",
        "  lab = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/all_labels.csv',names=header_list)\n",
        "  fake = 0\n",
        "  real = 0\n",
        "  for i in data_list:\n",
        "    temp_video = i.split('/')[-1]\n",
        "    \n",
        "    label = lab.iloc[(labels.loc[labels[\"File\"] == temp_video].index.values[0]),1]\n",
        "    if(label == 'FAKE'):\n",
        "      fake+=1\n",
        "    if(label == 'REAL'):\n",
        "      real+=1\n",
        "  return real,fake"
      ],
      "metadata": {
        "id": "8pitYdpLg3AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the labels and video in data loader\n",
        "header_list = [\"File\",\"Label\"]\n",
        "labels = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/all_labels.csv',names=header_list)\n",
        "\n",
        "train_videos = video_files[:int(0.8*len(video_files))]\n",
        "temp = video_files[int(0.8*len(video_files)):]\n",
        "valid_videos = temp[:int(0.5*len(temp))]\n",
        "test_videos = temp[int(0.5*len(temp)):]\n",
        "\n",
        "print(\"train : \" , len(train_videos))\n",
        "print(\"valid : \" , len(valid_videos))\n",
        "print(\"test : \",len(test_videos))\n",
        "\n",
        "real,fake = number_of_real_and_fake_videos(train_videos)\n",
        "print(\"TRAIN: \", \"Real:\",real,\" Fake:\",fake)\n",
        "real,fake = number_of_real_and_fake_videos(valid_videos)\n",
        "print(\"VALID: \", \"Real:\",real,\" Fake:\",fake)\n",
        "real,fake = number_of_real_and_fake_videos(test_videos)\n",
        "print(\"TEST: \", \"Real:\",real,\" Fake:\",fake)"
      ],
      "metadata": {
        "id": "k6HOWiHog7B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_size = 240\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage(),\n",
        "                                        transforms.Resize((im_size,im_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean,std)])\n",
        "\n",
        "\n",
        "train_data = video_dataset(train_videos,labels,sequence_length = 1,transform = transforms)\n",
        "#print(train_data)\n",
        "\n",
        "val_data = video_dataset(valid_videos,labels,sequence_length = 1,transform = transforms)\n",
        "test_data = video_dataset(test_videos,labels,sequence_length = 1,transform = transforms)\n",
        "\n",
        "train_loader = DataLoader(train_data,batch_size = 4,shuffle = True,num_workers = 4)\n",
        "valid_loader = DataLoader(val_data,batch_size = 4,shuffle = True,num_workers = 4)\n",
        "test_loader = DataLoader(test_data,batch_size = 4,shuffle = True,num_workers = 4)"
      ],
      "metadata": {
        "id": "8yZJKd-_g7tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet-pytorch\n",
        "from efficientnet_pytorch import EfficientNet"
      ],
      "metadata": {
        "id": "Tu782QqChAZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the pretrained EfficientNet model\n",
        "\n",
        "model = EfficientNet.from_pretrained('efficientnet-b1')\n",
        "\n",
        "# Freeze weights\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "in_features = model._fc.in_features\n",
        "\n",
        "\n",
        "# Defining Dense top layers after the convolutional layers\n",
        "model._fc = nn.Sequential(\n",
        "    nn.BatchNorm1d(num_features=in_features),    # normalise\n",
        "    nn.Linear(in_features, 512),                 # linear transformation\n",
        "    nn.ReLU(),                                   # activation function\n",
        "    nn.BatchNorm1d(512),                         # normalise\n",
        "    nn.Dropout(0.4),                             # During training, randomly zeroes some of the \n",
        "                                                 # elements of the input tensor with probability p \n",
        "                                                 # using samples from a Bernoulli distribution.\n",
        "    nn.Linear(512, 2),                           # linear transformation\n",
        "    \n",
        "    )\n",
        "\n",
        "print(model._fc)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n"
      ],
      "metadata": {
        "id": "cOyAv6KLhA92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input = torch.randn(10, 3, 380, 380).type(torch.cuda.FloatTensor)\n",
        "out = model(dummy_input)\n",
        "print(out)"
      ],
      "metadata": {
        "id": "C25BGvOwhDyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting loss function\n",
        "criterion_transfer = nn.CrossEntropyLoss()\n",
        "\n",
        "#using Adam classifier\n",
        "optimizer_transfer = optim.Adam(model.parameters(), lr=0.00001, weight_decay = 0.00001)\n",
        "\n",
        "n_epochs = 20\n"
      ],
      "metadata": {
        "id": "OUy8mcR_hHOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the function for training\n",
        "def train(n_epochs, train_loader,valid_loader, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    trainingloss = []\n",
        "    validationloss = []\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize the variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        \n",
        "        ###################\n",
        "        # training the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            # move to GPU\n",
        "            #print(data.shape)\n",
        "            batch,seq,c,h,w = data.shape\n",
        "            data = data.view(batch*seq, c, h, w)\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.type(torch.cuda.LongTensor)\n",
        "          \n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "           \n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "    \n",
        "        ######################    \n",
        "        # validating the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "            batch,seq,c,h,w = data.shape\n",
        "            data = data.view(batch*seq, c, h, w)\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            \n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "        \n",
        "        train_loss = train_loss/len(train_videos)\n",
        "        valid_loss = valid_loss/len(valid_videos)\n",
        "\n",
        "        trainingloss.append(train_loss)\n",
        "        validationloss.append(valid_loss)\n",
        "\n",
        "        # printing training/validation statistics \n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "       \n",
        "        ## saving the model if validation loss has decreased\n",
        "        if valid_loss < valid_loss_min:\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            \n",
        "            valid_loss_min = valid_loss\n",
        "            \n",
        "    # return trained model\n",
        "    return model, trainingloss, validationloss"
      ],
      "metadata": {
        "id": "xCAjp-64hHt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_transfer, train_loss, valid_loss = train(n_epochs, train_loader,valid_loader, model, optimizer_transfer, criterion_transfer, use_cuda, 'efficientnet-bx-2fc.pt')"
      ],
      "metadata": {
        "id": "X6Klt0aWhM_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model that got the best validation accuracy (uncomment the line below)\n",
        "model_transfer.load_state_dict(torch.load('efficientnet-bx-2fc.pt'))"
      ],
      "metadata": {
        "id": "vLJfIF4vhZ5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the test function\n",
        "\n",
        "def test(test_loader, model, criterion, use_cuda):\n",
        "\n",
        "    # monitoring test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    preds = []\n",
        "    targets = []\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        # moving to GPU\n",
        "        batch,seq,c,h,w = data.shape\n",
        "        data = data.view(batch*seq, c, h, w)\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # updating average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # converting the output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        preds.append(pred)\n",
        "        targets.append(target)\n",
        "        # compare predictions\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "    \n",
        "    return preds, targets\n",
        "\n",
        "# calling test function\n",
        "preds, targets = test(test_loader, model_transfer, criterion_transfer, use_cuda)\n"
      ],
      "metadata": {
        "id": "bEdy8cm1hhHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting the tensor object to a list for metric functions\n",
        "\n",
        "preds2, targets2 = [],[]\n",
        "\n",
        "for i in preds:\n",
        "  for j in range(len(i)):\n",
        "    preds2.append(i.cpu().numpy()[j])\n",
        "for i in targets:\n",
        "  for j in range(len(i)):\n",
        "    targets2.append(i.cpu().numpy()[j])"
      ],
      "metadata": {
        "id": "kSozmxv2hjvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "#Computing the accuracy\n",
        "acc = accuracy_score(targets2, preds2)\n",
        "print(\"Accuracy: \", acc)"
      ],
      "metadata": {
        "id": "Q_qhteV4hkla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(targets2, preds2)\n",
        "\n",
        "#Create an object for the confusion matrix display class\n",
        "cmob = ConfusionMatrixDisplay(cm, display_labels=['Real', 'Fake'])\n",
        "\n",
        "\n",
        "# The plot() function has to be called for the sklearn visualization\n",
        "cmob.plot()\n",
        "\n",
        "# Use the Axes attribute 'ax_' to get to the underlying Axes object.\n",
        "cmob.ax_.set(title='Confusion Matrix with labels', \n",
        "            xlabel='Predicted', \n",
        "            ylabel='Actual')\n",
        "\n",
        "# Finally, call the matplotlib show() function to display the visualization\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Le0HVl_bhnxG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}